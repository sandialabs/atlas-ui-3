# Atlas CLI and Python API

Last updated: 2026-01-27 20:30

## Overview

Atlas provides a non-interactive CLI and Python API for one-shot LLM chat with full MCP tools and RAG support -- no browser or WebSocket needed.

## Tool Naming Convention

Tool names are fully qualified as `{serverName}_{toolName}`, where `serverName` is the key in `mcp.json` and `toolName` is the function name registered in the MCP server.

Default servers from `config/defaults/mcp.json` and their tools:

| Server | Tool name(s) | Description |
|--------|-------------|-------------|
| `calculator` | `calculator_evaluate` | Evaluate math expressions |
| `pdfbasic` | `pdfbasic_*` | PDF text extraction and analysis |
| `code-executor` | `code-executor_*` | Sandboxed code execution |
| `ui-demo` | `ui-demo_*` | UI customization demo |
| `prompts` | (prompts only, no tools) | System prompt overrides |
| `env-demo` | `env-demo_*` | Environment variable demo |

The special pseudo-tool `canvas_canvas` is always available regardless of selection.

## CLI Usage

```bash
cd backend

# Basic prompt
python atlas_chat_cli.py "Summarize the latest docs" --model gpt-4o

# With tools
python atlas_chat_cli.py "What is 355/113?" --tools calculator_evaluate

# Multiple tools
python atlas_chat_cli.py "Calculate 2^10 then execute print('hello') in Python" \
  --tools calculator_evaluate,code-executor_execute_code

# Write output to file
python atlas_chat_cli.py "Generate a report" -o ./report.md

# Read prompt from stdin
echo "Explain quantum computing" | python atlas_chat_cli.py -

# JSON output (structured result with tool_calls, files, etc.)
python atlas_chat_cli.py "What is 2+2?" --tools calculator_evaluate --json

# Quiet mode (suppress tool/status output on stderr, only final response on stdout)
python atlas_chat_cli.py "What is 2+2?" --tools calculator_evaluate -q

# Reuse a session for multi-turn conversation
python atlas_chat_cli.py "Remember: my name is Alice" --session-id 550e8400-e29b-41d4-a716-446655440000
python atlas_chat_cli.py "What is my name?" --session-id 550e8400-e29b-41d4-a716-446655440000
```

### CLI Flags

| Flag | Description |
|------|-------------|
| `prompt` | Positional prompt text, or `-` for stdin |
| `--model` | LLM model name (default from config) |
| `--tools` | Comma-separated fully-qualified tool names (`serverName_toolName`) |
| `-o, --output` | Write response to file path |
| `--json` | Output structured JSON |
| `--session-id` | Reuse session UUID for multi-turn |
| `--max-steps` | Max agent iterations (default: 10) |
| `--user-email` | Override user identity |
| `-q, --quiet` | Suppress tool/status output |

### Exit Codes

- `0` - Success
- `1` - Runtime error
- `2` - Bad arguments (no prompt provided)

## Python API

```python
import asyncio
from atlas_client import AtlasClient

async def main():
    client = AtlasClient()
    result = await client.chat(
        prompt="What is 355 divided by 113?",
        model="gpt-4o",
        selected_tools=["calculator_evaluate"],
    )
    print(result.message)
    print(result.tool_calls)
    await client.cleanup()

asyncio.run(main())
```

### Using multiple tools

```python
result = await client.chat(
    prompt="Calculate 2^10 then run print('hello') in Python",
    selected_tools=["calculator_evaluate", "code-executor_execute_code"],
)
```

### Sync usage

```python
from atlas_client import AtlasClient

client = AtlasClient()
result = client.chat_sync(
    "What is 2+2?",
    model="gpt-4o",
    selected_tools=["calculator_evaluate"],
)
print(result.message)
```

### ChatResult fields

| Field | Type | Description |
|-------|------|-------------|
| `message` | `str` | Assistant's text response |
| `tool_calls` | `list[dict]` | Tool invocations with name, status, result |
| `files` | `dict` | Session files produced by tools |
| `canvas_content` | `str or None` | HTML/markdown canvas content |
| `session_id` | `UUID` | Session ID for multi-turn reuse |

## Configuration

The CLI uses the same configuration as the web app:
- `.env` for environment variables
- `config/defaults/` and `config/overrides/` for LLM, MCP, and RAG config
- MCP tool discovery runs automatically on first use
- Tool servers are defined in `config/defaults/mcp.json` (or `config/overrides/mcp.json`)

To see which tools are available, check the server keys in your `mcp.json` and the `@mcp.tool` decorated functions in each server's `main.py`.

## Use Cases

- **E2E testing**: Script chat interactions for automated testing
- **MCP development**: Test tool servers without starting the full UI
- **Scripted workflows**: Chain LLM calls in shell scripts or Python
- **CI/CD**: Validate LLM + tool integrations in pipelines
